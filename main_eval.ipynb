{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./module/config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "from module.data_loader import get_dataframe, get_dataset_test\n",
    "train_df, valid_df, test_df = get_dataframe(config[\"data_path\"], config[\"train_size\"])\n",
    "\n",
    "test_dataset = get_dataset_test(test_df, config[\"data_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    shuffle = False, \n",
    "    num_workers = config[\"num_workers\"],\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.custom_model import Model\n",
    "model = Model(config[\"mask_ratio\"], config[\"pretrained\"])\n",
    "\n",
    "model.load_state_dict(torch.load(config[\"model_save_path\"] + config[\"import_model_name\"]))\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=config[\"lr\"],\n",
    "                        weight_decay=config[\"weight_decay\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.calc_score import eval_model\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date = now.date()\n",
    "\n",
    "test_pred_df = eval_model(model, test_dataloader, test_df)\n",
    "test_pred_df.to_csv(config[\"result_save_path\"] + f'/submission_{date}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
